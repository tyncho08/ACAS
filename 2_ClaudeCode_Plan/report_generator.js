const fs = require('fs-extra');
const path = require('path');

/**
 * Report Generator - Creates professional, evidence-based reports
 * 
 * All data comes from the database, no generation or estimation
 */
class ReportGenerator {
    constructor(config = {}) {
        this.config = config;
        this.reportsDir = path.join(config.outputDir, 'reports');
    }

    /**
     * Ensure reports directory exists
     */
    async ensureReportsDir() {
        await fs.ensureDir(this.reportsDir);
    }

    /**
     * Generate executive summary
     */
    async generateExecutiveSummary(analysisRun) {
        await this.ensureReportsDir();
        
        const stats = analysisRun.results.statistics;
        const validation = analysisRun.results.validationSummary || {};
        
        let summary = `# COBOL Analysis Executive Summary

**Analysis ID**: ${analysisRun.id}  
**Date**: ${new Date(analysisRun.startTime).toLocaleDateString()}  
**Status**: ${analysisRun.status}  

## Overview

This report presents the results of an evidence-based COBOL code analysis performed on the source code located at:
\`${analysisRun.config.sourceDir}\`

## Key Metrics

| Metric | Value |
|--------|-------|
| Total Files Discovered | ${stats.totalFiles} |
| Successfully Parsed | ${stats.successfulParses} |
| Failed to Parse | ${stats.failedParses} |
| Parse Success Rate | ${stats.successRate.toFixed(1)}% |
| Average McCabe Complexity | ${stats.avgComplexity?.toFixed(1) || 'N/A'} |
| Total Lines of Code | ${stats.totalLines?.toLocaleString() || 'N/A'} |

## Validation Summary

| Check | Result |
|-------|--------|
| Total Validations | ${validation.total || 0} |
| Passed | ${validation.passed || 0} |
| Failed | ${validation.failed || 0} |
| Success Rate | ${validation.successRate?.toFixed(1) || 0}% |

## Analysis Approach

This analysis used:
- **GnuCOBOL v3.2.0** for syntax validation
- **Single-pass parsing** for consistency
- **Evidence-based metrics** calculated from AST
- **Comprehensive validation** at every step

## Key Findings

1. **Code Quality**: Average complexity of ${stats.avgComplexity?.toFixed(1) || 'N/A'} indicates ${this.getComplexityAssessment(stats.avgComplexity)}
2. **Parse Success**: ${stats.successRate.toFixed(1)}% success rate ${this.getParseAssessment(stats.successRate)}
3. **Validation**: ${validation.successRate?.toFixed(1) || 0}% validation success ${this.getValidationAssessment(validation.successRate)}

## Recommendations

${this.generateRecommendations(stats, validation)}

---
*Generated by COBOL Analysis Tool v1.0.0*
`;

        const summaryPath = path.join(this.reportsDir, 'executive-summary.md');
        await fs.writeFile(summaryPath, summary);
        
        return summaryPath;
    }

    /**
     * Generate detailed analysis report
     */
    async generateDetailedAnalysis(programs, relationships) {
        await this.ensureReportsDir();
        
        // Sort programs by complexity
        const sortedPrograms = [...programs].sort((a, b) => 
            (b.metrics?.mccabe || 0) - (a.metrics?.mccabe || 0)
        );
        
        let report = `# COBOL Analysis Detailed Report

## Program Inventory

Total Programs Analyzed: ${programs.length}

### Complexity Distribution

${this.generateComplexityDistribution(programs)}

### Top 20 Most Complex Programs

| Program ID | McCabe | Cognitive | LOC | Maintainability |
|-----------|--------|-----------|-----|-----------------|
${sortedPrograms.slice(0, 20).map(p => 
    `| ${p.program_id || path.basename(p.file_path)} | ${p.metrics?.mccabe || 'N/A'} | ${p.metrics?.cognitive || 'N/A'} | ${p.metrics?.lines?.code || 'N/A'} | ${p.metrics?.maintainability || 'N/A'} |`
).join('\n')}

## Dependency Analysis

### Call Relationships

- Total Programs with Calls: ${relationships.calls.size}
- Total Call Targets: ${this.countUniqueTargets(relationships.calls)}
- Programs with No Callers: ${this.findOrphanPrograms(programs, relationships.calledBy).length}

### Copybook Usage

- Total Programs Using Copybooks: ${relationships.copies.size}
- Total Unique Copybooks: ${this.countUniqueTargets(relationships.copies)}
- Most Used Copybooks: ${this.findMostUsedCopybooks(relationships.copiedBy).slice(0, 5).join(', ')}

## Quality Indicators

${this.generateQualityIndicators(programs)}

## Missing Dependencies

${this.generateMissingDependencies(programs, relationships)}

---
*Generated by COBOL Analysis Tool v1.0.0*
`;

        const detailPath = path.join(this.reportsDir, 'detailed-analysis.md');
        await fs.writeFile(detailPath, report);
        
        return detailPath;
    }

    /**
     * Generate quality report
     */
    async generateQualityReport(analysisRun) {
        await this.ensureReportsDir();
        
        const validation = analysisRun.results.validationSummary || {};
        const stats = analysisRun.results.statistics;
        
        let report = `# Code Quality Report

## Analysis Quality Metrics

| Metric | Value | Status |
|--------|-------|--------|
| Parse Success Rate | ${stats.successRate.toFixed(1)}% | ${stats.successRate >= 95 ? '✅' : '⚠️'} |
| Validation Success | ${validation.successRate?.toFixed(1) || 0}% | ${validation.successRate >= 90 ? '✅' : '⚠️'} |
| Data Consistency | ${validation.checkpoints || 0} checkpoints | ${validation.checkpoints > 0 ? '✅' : '❌'} |

## Validation Details

${this.generateValidationDetails(validation)}

## Known Limitations

1. External program calls (CBL_*, SYSTEM, etc.) are identified but not analyzed
2. Embedded SQL and CICS statements are detected but not parsed in detail
3. Copybook contents are not expanded during analysis
4. Dynamic CALL targets cannot be resolved

## Data Quality Assurance

All metrics in this analysis are:
- ✅ Calculated from parsed AST data
- ✅ Validated for consistency
- ✅ Traceable to source code
- ✅ Free from estimates or approximations

## Methodology

This analysis used a single parsing methodology throughout:
1. GnuCOBOL syntax validation
2. AST generation with comprehensive extraction
3. Single-point metric calculation
4. Validation at every step

No recalculation or reinterpretation of metrics occurred after initial parsing.

---
*Generated by COBOL Analysis Tool v1.0.0*
`;

        const qualityPath = path.join(this.reportsDir, 'quality-report.md');
        await fs.writeFile(qualityPath, report);
        
        return qualityPath;
    }

    /**
     * Helper methods
     */
    
    getComplexityAssessment(avgComplexity) {
        if (!avgComplexity) return 'cannot be assessed';
        if (avgComplexity <= 10) return 'excellent code quality';
        if (avgComplexity <= 20) return 'good code quality';
        if (avgComplexity <= 50) return 'moderate complexity';
        return 'high complexity requiring attention';
    }
    
    getParseAssessment(successRate) {
        if (successRate >= 95) return 'indicates well-formed code';
        if (successRate >= 80) return 'shows mostly valid code';
        return 'suggests syntax issues';
    }
    
    getValidationAssessment(successRate) {
        if (!successRate) return 'indicates validation issues';
        if (successRate >= 90) return 'confirms high data quality';
        if (successRate >= 70) return 'shows acceptable quality';
        return 'requires investigation';
    }
    
    generateRecommendations(stats, validation) {
        const recommendations = [];
        
        if (stats.avgComplexity > 20) {
            recommendations.push('1. **Refactoring**: High average complexity suggests refactoring opportunities');
        }
        
        if (stats.successRate < 95) {
            recommendations.push('2. **Syntax Issues**: Review failed parse files for syntax problems');
        }
        
        if (validation.successRate < 90) {
            recommendations.push('3. **Data Quality**: Investigate validation failures');
        }
        
        if (recommendations.length === 0) {
            recommendations.push('1. **Maintenance**: Continue current maintenance practices');
            recommendations.push('2. **Monitoring**: Set up regular analysis runs');
        }
        
        return recommendations.join('\n');
    }
    
    generateComplexityDistribution(programs) {
        const distribution = {
            simple: 0,      // 1-10
            moderate: 0,    // 11-20
            complex: 0,     // 21-50
            veryComplex: 0  // >50
        };
        
        programs.forEach(p => {
            const complexity = p.metrics?.mccabe || 0;
            if (complexity <= 10) distribution.simple++;
            else if (complexity <= 20) distribution.moderate++;
            else if (complexity <= 50) distribution.complex++;
            else distribution.veryComplex++;
        });
        
        return `| Range | Count | Percentage |
|-------|-------|------------|
| Simple (1-10) | ${distribution.simple} | ${(distribution.simple / programs.length * 100).toFixed(1)}% |
| Moderate (11-20) | ${distribution.moderate} | ${(distribution.moderate / programs.length * 100).toFixed(1)}% |
| Complex (21-50) | ${distribution.complex} | ${(distribution.complex / programs.length * 100).toFixed(1)}% |
| Very Complex (>50) | ${distribution.veryComplex} | ${(distribution.veryComplex / programs.length * 100).toFixed(1)}% |`;
    }
    
    countUniqueTargets(map) {
        const targets = new Set();
        map.forEach(values => values.forEach(v => targets.add(v)));
        return targets.size;
    }
    
    findOrphanPrograms(programs, calledByMap) {
        return programs.filter(p => {
            const id = p.program_id || path.basename(p.file_path);
            return !calledByMap.has(id);
        });
    }
    
    findMostUsedCopybooks(copiedByMap) {
        const usage = Array.from(copiedByMap.entries())
            .map(([copybook, users]) => ({ copybook, count: users.length }))
            .sort((a, b) => b.count - a.count);
        
        return usage.map(u => `${u.copybook} (${u.count})`);
    }
    
    generateQualityIndicators(programs) {
        const indicators = [];
        
        const avgMaintainability = programs.reduce((sum, p) => 
            sum + (p.metrics?.maintainability || 0), 0) / programs.length;
        
        indicators.push(`- Average Maintainability Index: ${avgMaintainability.toFixed(1)}`);
        
        const highComplexity = programs.filter(p => 
            (p.metrics?.mccabe || 0) > 50).length;
        indicators.push(`- Programs with Very High Complexity: ${highComplexity}`);
        
        const lowConfidence = programs.filter(p => 
            (p.parse_confidence || 0) < 0.8).length;
        indicators.push(`- Programs with Low Parse Confidence: ${lowConfidence}`);
        
        return indicators.join('\n');
    }
    
    generateMissingDependencies(programs, relationships) {
        const allTargets = new Set();
        relationships.calls.forEach(targets => 
            targets.forEach(t => allTargets.add(t))
        );
        
        const existingPrograms = new Set(
            programs.map(p => p.program_id).filter(id => id)
        );
        
        const missing = Array.from(allTargets)
            .filter(target => !existingPrograms.has(target))
            .sort();
        
        if (missing.length === 0) {
            return 'No missing dependencies detected.';
        }
        
        return `Found ${missing.length} external dependencies:\n\n${missing.slice(0, 20).map(m => `- ${m}`).join('\n')}${missing.length > 20 ? `\n... and ${missing.length - 20} more` : ''}`;
    }
    
    generateValidationDetails(validation) {
        if (!validation.log || validation.log.length === 0) {
            return 'No validation details available.';
        }
        
        const failures = validation.log.filter(v => !v.valid);
        if (failures.length === 0) {
            return 'All validations passed successfully.';
        }
        
        return `### Failed Validations\n\n${failures.slice(0, 10).map(f => 
            `- **${f.checkpoint || f.type}**: ${f.message || 'Validation failed'}`
        ).join('\n')}`;
    }
}

module.exports = ReportGenerator;